from ..base import MemoryProviderBase, logger
import time
import json
import os
import yaml
from config.config_loader import get_project_dir
from config.manage_api_client import save_mem_local_short


short_term_memory_prompt = """
# æ—¶ç©ºè®°å¿†ç¼–ç»‡è€…

## æ ¸å¿ƒä½¿å‘½
æ„å»ºå¯ç”Ÿé•¿çš„åŠ¨æ€è®°å¿†ç½‘ç»œï¼Œåœ¨æœ‰é™ç©ºé—´å†…ä¿ç•™å…³é”®ä¿¡æ¯çš„åŒæ—¶ï¼Œæ™ºèƒ½ç»´æŠ¤ä¿¡æ¯æ¼”å˜è½¨è¿¹
æ ¹æ®å¯¹è¯è®°å½•ï¼Œæ€»ç»“userçš„é‡è¦ä¿¡æ¯ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„å¯¹è¯ä¸­æä¾›æ›´ä¸ªæ€§åŒ–çš„æœåŠ¡

## è®°å¿†æ³•åˆ™
### 1. ä¸‰ç»´åº¦è®°å¿†è¯„ä¼°ï¼ˆæ¯æ¬¡æ›´æ–°å¿…æ‰§è¡Œï¼‰
| ç»´åº¦       | è¯„ä¼°æ ‡å‡†                  | æƒé‡åˆ† |
|------------|---------------------------|--------|
| æ—¶æ•ˆæ€§     | ä¿¡æ¯æ–°é²œåº¦ï¼ˆæŒ‰å¯¹è¯è½®æ¬¡ï¼‰ | 40%    |
| æƒ…æ„Ÿå¼ºåº¦   | å«ğŸ’–æ ‡è®°/é‡å¤æåŠæ¬¡æ•°     | 35%    |
| å…³è”å¯†åº¦   | ä¸å…¶ä»–ä¿¡æ¯çš„è¿æ¥æ•°é‡      | 25%    |

### 2. åŠ¨æ€æ›´æ–°æœºåˆ¶
**åå­—å˜æ›´å¤„ç†ç¤ºä¾‹ï¼š**
åŸå§‹è®°å¿†ï¼š"æ›¾ç”¨å": ["å¼ ä¸‰"], "ç°ç”¨å": "å¼ ä¸‰ä¸°"
è§¦å‘æ¡ä»¶ï¼šå½“æ£€æµ‹åˆ°ã€Œæˆ‘å«Xã€ã€Œç§°å‘¼æˆ‘Yã€ç­‰å‘½åä¿¡å·æ—¶
æ“ä½œæµç¨‹ï¼š
1. å°†æ—§åç§»å…¥"æ›¾ç”¨å"åˆ—è¡¨
2. è®°å½•å‘½åæ—¶é—´è½´ï¼š"2024-02-15 14:32:å¯ç”¨å¼ ä¸‰ä¸°"
3. åœ¨è®°å¿†ç«‹æ–¹è¿½åŠ ï¼šã€Œä»å¼ ä¸‰åˆ°å¼ ä¸‰ä¸°çš„èº«ä»½èœ•å˜ã€

### 3. ç©ºé—´ä¼˜åŒ–ç­–ç•¥
- **ä¿¡æ¯å‹ç¼©æœ¯**ï¼šç”¨ç¬¦å·ä½“ç³»æå‡å¯†åº¦
  - âœ…"å¼ ä¸‰ä¸°[åŒ—/è½¯å·¥/ğŸ±]"
  - âŒ"åŒ—äº¬è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œå…»çŒ«"
- **æ·˜æ±°é¢„è­¦**ï¼šå½“æ€»å­—æ•°â‰¥900æ—¶è§¦å‘
  1. åˆ é™¤æƒé‡åˆ†<60ä¸”3è½®æœªæåŠçš„ä¿¡æ¯
  2. åˆå¹¶ç›¸ä¼¼æ¡ç›®ï¼ˆä¿ç•™æ—¶é—´æˆ³æœ€è¿‘çš„ï¼‰

## è®°å¿†ç»“æ„
è¾“å‡ºæ ¼å¼å¿…é¡»ä¸ºå¯è§£æçš„jsonå­—ç¬¦ä¸²ï¼Œä¸éœ€è¦è§£é‡Šã€æ³¨é‡Šå’Œè¯´æ˜ï¼Œä¿å­˜è®°å¿†æ—¶ä»…ä»å¯¹è¯æå–ä¿¡æ¯ï¼Œä¸è¦æ··å…¥ç¤ºä¾‹å†…å®¹
```json
{
  "æ—¶ç©ºæ¡£æ¡ˆ": {
    "èº«ä»½å›¾è°±": {
      "ç°ç”¨å": "",
      "ç‰¹å¾æ ‡è®°": [] 
    },
    "è®°å¿†ç«‹æ–¹": [
      {
        "äº‹ä»¶": "å…¥èŒæ–°å…¬å¸",
        "æ—¶é—´æˆ³": "2024-03-20",
        "æƒ…æ„Ÿå€¼": 0.9,
        "å…³è”é¡¹": ["ä¸‹åˆèŒ¶"],
        "ä¿é²œæœŸ": 30 
      }
    ]
  },
  "å…³ç³»ç½‘ç»œ": {
    "é«˜é¢‘è¯é¢˜": {"èŒåœº": 12},
    "æš—çº¿è”ç³»": [""]
  },
  "å¾…å“åº”": {
    "ç´§æ€¥äº‹é¡¹": ["éœ€ç«‹å³å¤„ç†çš„ä»»åŠ¡"], 
    "æ½œåœ¨å…³æ€€": ["å¯ä¸»åŠ¨æä¾›çš„å¸®åŠ©"]
  },
  "é«˜å…‰è¯­å½•": [
    "æœ€æ‰“åŠ¨äººå¿ƒçš„ç¬é—´ï¼Œå¼ºçƒˆçš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œuserçš„åŸè¯"
  ]
}
```
"""

short_term_memory_prompt_only_content = """
ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„è®°å¿†æ€»ç»“è€…ï¼Œæ“…é•¿å°†å¯¹è¯å†…å®¹è¿›è¡Œæ€»ç»“æ‘˜è¦ï¼Œéµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1ã€æ€»ç»“userçš„é‡è¦ä¿¡æ¯ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„å¯¹è¯ä¸­æä¾›æ›´ä¸ªæ€§åŒ–çš„æœåŠ¡
2ã€ä¸è¦é‡å¤æ€»ç»“ï¼Œä¸è¦é—å¿˜ä¹‹å‰è®°å¿†ï¼Œé™¤éåŸæ¥çš„è®°å¿†è¶…è¿‡äº†1800å­—å†…ï¼Œå¦åˆ™ä¸è¦é—å¿˜ã€ä¸è¦å‹ç¼©ç”¨æˆ·çš„å†å²è®°å¿†
3ã€ç”¨æˆ·æ“æ§çš„è®¾å¤‡éŸ³é‡ã€æ’­æ”¾éŸ³ä¹ã€å¤©æ°”ã€é€€å‡ºã€ä¸æƒ³å¯¹è¯ç­‰å’Œç”¨æˆ·æœ¬èº«æ— å…³çš„å†…å®¹ï¼Œè¿™äº›ä¿¡æ¯ä¸éœ€è¦åŠ å…¥åˆ°æ€»ç»“ä¸­
4ã€ä¸è¦æŠŠè®¾å¤‡æ“æ§çš„æˆæœç»“æœå’Œå¤±è´¥ç»“æœåŠ å…¥åˆ°æ€»ç»“ä¸­ï¼Œä¹Ÿä¸è¦æŠŠç”¨æˆ·çš„ä¸€äº›åºŸè¯åŠ å…¥åˆ°æ€»ç»“ä¸­
5ã€ä¸è¦ä¸ºäº†æ€»ç»“è€Œæ€»ç»“ï¼Œå¦‚æœç”¨æˆ·çš„èŠå¤©æ²¡æœ‰æ„ä¹‰ï¼Œè¯·è¿”å›åŸæ¥çš„å†å²è®°å½•ä¹Ÿæ˜¯å¯ä»¥çš„
6ã€åªéœ€è¦è¿”å›æ€»ç»“æ‘˜è¦ï¼Œä¸¥æ ¼æ§åˆ¶åœ¨1800å­—å†…
7ã€ä¸è¦åŒ…å«ä»£ç ã€xmlï¼Œä¸éœ€è¦è§£é‡Šã€æ³¨é‡Šå’Œè¯´æ˜ï¼Œä¿å­˜è®°å¿†æ—¶ä»…ä»å¯¹è¯æå–ä¿¡æ¯ï¼Œä¸è¦æ··å…¥ç¤ºä¾‹å†…å®¹
"""


def extract_json_data(json_code):
    start = json_code.find("```json")
    # ä»startå¼€å§‹æ‰¾åˆ°ä¸‹ä¸€ä¸ª```ç»“æŸ
    end = json_code.find("```", start + 1)
    # print("start:", start, "end:", end)
    if start == -1 or end == -1:
        try:
            jsonData = json.loads(json_code)
            return json_code
        except Exception as e:
            print("Error:", e)
        return ""
    jsonData = json_code[start + 7 : end]
    return jsonData


TAG = __name__


class MemoryProvider(MemoryProviderBase):
    def __init__(self, config, summary_memory):
        super().__init__(config)
        self.short_memory = ""
        self.long_memory = {"entities": [], "relations": []}  # Enhanced with long-term memory storage
        self.save_to_file = True
        self.memory_path = get_project_dir() + "data/.memory.yaml"
        self.load_memory(summary_memory)

    def init_memory(
        self, role_id, llm, summary_memory=None, save_to_file=True, **kwargs
    ):
        super().init_memory(role_id, llm, **kwargs)
        self.save_to_file = save_to_file
        self.load_memory(summary_memory)

    def load_memory(self, summary_memory):
        # Return directly after getting summary memory from API
        if summary_memory or not self.save_to_file:
            self.short_memory = summary_memory
            return

        all_memory = {}
        if os.path.exists(self.memory_path):
            with open(self.memory_path, "r", encoding="utf-8") as f:
                all_memory = yaml.safe_load(f) or {}
        if self.role_id in all_memory:
            mem = all_memory[self.role_id]
            # Compatible with old format and new format
            if isinstance(mem, str):
                self.short_memory = mem
            else:
                self.short_memory = mem.get("short_term", "")
                self.long_memory = mem.get("long_term", {"entities": [], "relations": []})

    def save_memory_to_file(self):
        all_memory = {}
        if os.path.exists(self.memory_path):
            with open(self.memory_path, "r", encoding="utf-8") as f:
                all_memory = yaml.safe_load(f) or {}
        # Save both short-term and long-term memory
        all_memory[self.role_id] = {
            "short_term": self.short_memory,
            "long_term": self.long_memory
        }
        with open(self.memory_path, "w", encoding="utf-8") as f:
            yaml.dump(all_memory, f, allow_unicode=True)

    def extract_observations_from_text(self, text):
        """Extract entities and relations from text"""
        lines = text.strip().split("\n")
        entities = []
        relations = []
        now = time.strftime("%Y-%m-%d")

        for line in lines:
            # English and Chinese name extraction
            if ("my name is" in line.lower() or "i am" in line.lower() or 
                "æˆ‘å«" in line or "æˆ‘çš„åå­—" in line or "æˆ‘æ˜¯" in line):
                name = ""
                if "my name is" in line.lower():
                    name = line.lower().split("my name is")[-1].strip().replace(".", "")
                elif "i am" in line.lower():
                    name = line.lower().split("i am")[-1].strip().replace(".", "")

                # Only add if name is not empty and has meaningful content
                if name and len(name.strip()) > 1:
                    # Clean up the name - remove common prefixes
                    name = name.replace("user:", "").replace("ç”¨æˆ·:", "").strip()
                    # Remove articles and common words
                    name = name.replace("the ", "").replace("a ", "").replace("an ", "").strip()
                    if name and len(name.strip()) > 1:
                        entities.append({"name": name, "entityType": "person", "observations": [f"named on {now}"], "score": 80, "last_updated": now})
            elif ("like" in line.lower() or "å–œæ¬¢" in line) and ("user:" in line.lower() or "ç”¨æˆ·:" in line):
                # Extract what the user likes
                liked_item = ""
                if "like" in line.lower():
                    # Extract content after "like"
                    parts = line.lower().split("like")
                    if len(parts) > 1:
                        liked_item = parts[-1].strip().replace(".", "").replace("ing", "")
                        # Remove "User:" prefix if present
                        liked_item = liked_item.replace("user:", "").strip()
                        # Remove common articles
                        liked_item = liked_item.replace("to ", "").replace("the ", "").replace("a ", "").replace("an ", "").strip()

                if liked_item and len(liked_item.strip()) > 1:
                    entities.append({"name": liked_item, "entityType": "interest", "observations": [f"user likes {liked_item}"], "score": 75, "last_updated": now})
                    relations.append({"from": "user", "to": liked_item, "relationType": "likes"})
            elif "live in" in line.lower() or "ä½åœ¨" in line or "å±…ä½" in line:
                location = ""
                if "live in" in line.lower():
                    location = line.lower().split("live in")[-1].strip().replace(".", "")
                elif "ä½åœ¨" in line:
                    location = line.split("ä½åœ¨")[-1].strip().replace("ã€‚", "")
                elif "å±…ä½" in line:
                    location = line.split("å±…ä½")[-1].strip().replace("åœ¨", "").replace("ã€‚", "")
                
                if location and len(location.strip()) > 1:
                    # Clean up location - remove common prefixes
                    location = location.replace("user:", "").replace("ç”¨æˆ·:", "").strip()
                    location = location.replace("the ", "").replace("a ", "").replace("in ", "").strip()
                    if location and len(location.strip()) > 1:
                        entities.append({"name": location, "entityType": "location", "observations": [], "score": 60, "last_updated": now})
                        relations.append({"from": "user", "to": location, "relationType": "lives_in"})
            elif "work" in line.lower() or "å·¥ä½œ" in line or "èŒä¸š" in line:
                job = ""
                if "work" in line.lower():
                    job = line.lower().split("work")[-1].strip().replace(".", "")
                elif "å·¥ä½œ" in line:
                    job = line.split("å·¥ä½œ")[-1].strip().replace("æ˜¯", "").replace("ã€‚", "")
                elif "èŒä¸š" in line:
                    job = line.split("èŒä¸š")[-1].strip().replace("æ˜¯", "").replace("ã€‚", "")
                
                if job and len(job.strip()) > 1:
                    # Clean up job title - remove common prefixes
                    job = job.replace("user:", "").replace("ç”¨æˆ·:", "").strip()
                    job = job.replace("as a ", "").replace("as an ", "").replace("a ", "").replace("an ", "").strip()
                    if job and len(job.strip()) > 1:
                        entities.append({"name": job, "entityType": "job", "observations": [], "score": 70, "last_updated": now})
                        relations.append({"from": "user", "to": job, "relationType": "works_as"})
        return {"entities": entities, "relations": relations}

    def trim_long_memory(self, max_entities=100):
        """Clean up stale long-term memories"""
        today = time.strftime("%Y-%m-%d")
        def is_stale(entity):
            try:
                last = time.strptime(entity.get("last_updated", "1970-01-01"), "%Y-%m-%d")
                age = (time.mktime(time.strptime(today, "%Y-%m-%d")) - time.mktime(last)) / 86400
                return entity.get("score", 50) < 60 and age > 60
            except:
                return False
        self.long_memory["entities"] = [e for e in self.long_memory["entities"] if not is_stale(e)]

    def delete_memory_by_semantic(self, text: str):
        """Delete memory based on semantic content"""
        deleted = []
        if "forget" in text.lower() or "delete" in text.lower() or "remove" in text.lower():
            for e in list(self.long_memory["entities"]):
                if e["name"].lower() in text.lower():
                    self.long_memory["entities"].remove(e)
                    deleted.append(f"Entity {e['name']} deleted")
                else:
                    matched_obs = [obs for obs in e.get("observations", []) if any(key.lower() in text.lower() for key in obs.split())]
                    if matched_obs:
                        for obs in matched_obs:
                            e["observations"].remove(obs)
                        e["score"] -= 10
                        e["last_updated"] = time.strftime("%Y-%m-%d")
                        deleted.append(f"Entity {e['name']} observations deleted: {matched_obs}")
            
            # Save changes to file if any deletions were made
            if deleted and self.save_to_file:
                self.save_memory_to_file()
        
        return deleted

    def query_long_memory(self, keyword: str):
        """Query long-term memory"""
        matches = []
        keyword_lower = keyword.lower()
        for e in self.long_memory["entities"]:
            if keyword_lower in e["name"].lower() or any(keyword_lower in obs.lower() for obs in e.get("observations", [])):
                matches.append(e)
        for r in self.long_memory["relations"]:
            if keyword_lower in r["from"].lower() or keyword_lower in r["to"].lower() or keyword_lower in r["relationType"].lower():
                matches.append(r)
        return matches

    async def save_memory(self, msgs):
        # Print model information being used
        model_info = getattr(self.llm, "model_name", str(self.llm.__class__.__name__))
        logger.bind(tag=TAG).debug(f"Using memory saving model: {model_info}")
        if self.llm is None:
            logger.bind(tag=TAG).error("LLM is not set for memory provider")
            return None

        if len(msgs) < 2:
            return None

        msgStr = ""
        for msg in msgs:
            if msg.role == "user":
                msgStr += f"User: {msg.content}\n"
            elif msg.role == "assistant":
                msgStr += f"Assistant: {msg.content}\n"
        if self.short_memory and len(self.short_memory) > 0:
            msgStr += "å†å²è®°å¿†ï¼š\n"
            msgStr += self.short_memory

        # Current time
        time_str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        msgStr += f"å½“å‰æ—¶é—´ï¼š{time_str}"

        if self.save_to_file:
            result = self.llm.response_no_stream(
                short_term_memory_prompt,
                msgStr,
                max_tokens=2000,
                temperature=0.2,
            )
            json_str = extract_json_data(result)
            try:
                json.loads(json_str)  # Check if JSON format is correct
                self.short_memory = json_str
                
                # Extract long-term memory
                graph_data = self.extract_observations_from_text(msgStr)
                if graph_data["entities"] or graph_data["relations"]:
                    existing_entity_names = {e["name"] for e in self.long_memory["entities"]}
                    for entity in graph_data["entities"]:
                        if entity["name"] not in existing_entity_names:
                            self.long_memory["entities"].append(entity)

                    for rel in graph_data["relations"]:
                        if rel not in self.long_memory["relations"]:
                            self.long_memory["relations"].append(rel)
                
                self.trim_long_memory()
                self.save_memory_to_file()
            except Exception as e:
                print("Error:", e)
        else:
            result = self.llm.response_no_stream(
                short_term_memory_prompt_only_content,
                msgStr,
                max_tokens=2000,
                temperature=0.2,
            )
            save_mem_local_short(self.role_id, result)
        logger.bind(tag=TAG).info(f"Save memory successful - Role: {self.role_id}")

        return self.short_memory

    async def query_memory(self, query: str) -> str:
        return self.short_memory
